---
title: "Ethics and Data Science"
author: "Mike;Mason, Hilary;Patil, DJ Loukides"
last_interaction: "Dienstag, 28. Dezember 2021 08:04:45"
---


Ethics really isn’t about agreeing to a set of principles. It’s about changing the way you act.

It’s also important to realize that ethics isn’t about a fixed list of do’s and don’ts. It’s primarily about having a discussion about how what you’re doing will affect other people, and whether those effects are acceptable.

Defining “fairness” is difficult, and perhaps impossible, given the many crosscutting layers of “fairness” that we might be concerned with.

Computer security has shown us the consequences of ignoring the consequences: many companies that have never taken the time to implement good security practices and safeguards are now paying with damage to their reputations and their finances.

But plenty of unintended consequences could easily have been foreseen: for example, Facebook’s “Year in Review” that reminded people of deaths and other painful events. Moving fast and breaking things is unacceptable if we don’t think about the things we are likely to break.

Oaths can actually give cover to people and organizations who are doing unethical work. It’s easy to think “we can’t be unethical, because we endorsed this oath.” It’s not enough to say “don’t be evil.” You have to not be evil.

Gawande found that, simply by creating checklists for basic things you shouldn’t forget, these mistakes could be eliminated almost completely.

Unlike oaths, checklists connect principle to practice.

Here’s a checklist for people who are working on data projects:

There’s no simple way to regain users’ trust, but we’d like to suggest a “golden rule” for data as a starting point: “treat others’ data as you would have others treat your own data.”

Five framing guidelines help us think about building data products. We call them the five Cs: consent, clarity, consistency, control (and transparency), and consequences (and harm). They’re a framework for implementing the golden rule for data.

people like John Wilbanks are working to develop models that help users to understand the implications of their choices. Wilbanks’ work helps people understand what happens when they provide sensitive medical and health data to a service.

Trust requires consistency over time. You can’t trust someone who is unpredictable.

All too often, users have no effective control over how their data is used. They are given all-or-nothing choices, or a convoluted set of options that make controlling access overwhelming and confusing.

it is essential to ask whether the data that is being collected could cause harm to an individual or a group.

The Fairness, Accountability, and Transparency in Machine Learning group (FAT/ML) advocates a similar approach. Their Principles for Accountable Algorithms and a Social Impact Statement for Algorithms suggests assessing the social impact statement of a project at least three times during its life: during design, pre-launch, and post-launch.

In a similar vein, the Community Principles on Ethical Data Practices, which arose out of the Data for Good Exchange (D4GX), provides a set of values and principles that have been gathered through community discussion.

An ethical challenge should be part of the hiring

Assume we have a large set of demographic data. We’re trying to evaluate individuals and we’re not supposed to use race as an input. However, you discover a proxy for race with the other variables. What would you do?

Product reviews must ask questions about the product’s impact.

This is the best single thing you can do to further data ethics: talk about it in meetings, at lunch, and even at dinner.
