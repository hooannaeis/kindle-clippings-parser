---
title: "The AI Mirror"
author: "Shannon Vallor"
last_interaction: "Mittwoch, 27. August 2025 23:22:33"
---


# Preface

AI is the first technology that can make us forget how to answer our own question.

Politically and morally, there has never been one “we.” There have only been those few who had the power and audacity to speak for the rest without asking.

# Introduction

AI systems mirror our own intelligence back to us.

This book tells a story of humanity increasingly lost in its own reflected image,

AI holds us frozen in place, fascinated by endless permutations of a reflected past that only the magic of marketing can disguise as the future.

Like all technologies, mirrors not only reflect us—they change us. Mirrors bring to our attention things we might otherwise have ignored.

Chapter 1 The AI Mirror

A metaphor draws a comparison between two things that are not literally of the same kind yet have parallel features that allow our understanding of one thing to carry over to and illuminate the other.

The history of AI, as a legitimate field of scientific research aimed at machine cognition, dates to the summer of 1956, when the first academic conference on this subject was held at Dartmouth College in the United States.

The true barrier to AGI is that AI tools today lack any lived experience, or even a coherent mental model, of what their data represent: the world beyond the bits stored on the server

“It is thus a bit akin to a mirror: it gives the illusion of depth and can reflect almost anything, but it is only a centimeter thick. If we try to explore its depths, we bump our heads.”

# Chapter 2 Minds, Machines, and Gods

Even still, bias in AI, whether it unjustly punishes us for our race, age, weight, gender, religion, disability status, or economic class, is not a computer problem. It’s a people problem. It is an example of the virtually universal explanation for all undesirable computer outputs not related to mechanical hardware failure: the computer did precisely what we told it to do, just not what we thought we had told it to do.

Much of software engineering is simply figuring out how to close the gap between those two things.

AI mirrors are profoundly conservative seers.15 That is, they are literally built to conserve the patterns of the past and extend them into our futures

Chapter 3 Through the Looking Glass

We can think of virtues as our moral and intellectual muscles, which like physical muscles must be actively cultivated and strengthened by activity. So, most of our valued traits, like honesty and courage, are only weakly present as dispositions in children, while some virtues, like wisdom, are thought to be virtually absent in the very young.

Why is the drunk man searching for his lost car keys under the lamppost? Because that’s where the light is.

Why do so few depictions of AGI show us a superhuman intelligence that laughs more than we do? Where are the intelligent machines not on a mission, but mastering being silly, goofing off, exploring, playing?

We must not take the mirror of human history as a doomed blueprint for AGI, or for ourselves. But to do otherwise, we first need to challenge the way we use today’s AI tools. Increasingly they function in our hands not as mirrors of prudence, but as engines of automated decision-making that engrave ever deeper into the world the patterns of our past failures.

Chapter 4 The Thoughts the Civilized Keep

Both the term (which first appears in late-medieval Latin, named for the ninth-century mathematician al-Khwārizmī) and its referents (which include the earliest mathematical procedures for counting, addition, and division) long predate modern computing.

> ultimate consequencd of relying exlusively on AI

We are addressed in the space of reasons whenever we are asked questions like, “Why have you done this to me?”, “Why should we believe that?”, “Why should we do that?”, “What could justify that?”, or “Why is this good?” Try for a moment to envision a society that can no longer meaningfully ask or answer such questions.

As philosophers Bert Heinrichs and Sebastian Knell argued in their 2021 paper “Aliens in the Space of Reasons?”, the kinds of computational tools that we call AI are wholly incapable of standing with us in the space of reasons. One of the most powerful yet dangerous aspects of complex machine learning models is that they can derive solutions to knowledge tasks in a manner that entirely bypasses this space. AI tools can produce outputs in the form of reasons (claims, arguments, objections, justifications) that very much mirror our own. But they do this without replicating human thought processes. It’s like the difference between building a cabin by cutting down, splitting, and fastening logs, and erecting a prefabricated cabin made of premixed wood laminate that was extruded and baked in a mold.

This is why, as we saw in Chapter 1, large language models struggle to defend even the answers they get right. It’s hard to rationally defend an answer that wasn’t constructed with reasons.

In his 1955 short story “Franchise,” the science fiction writer Isaac Asimov introduced us to Norman Muller.

No credible AI researchers are claiming that any computer currently in operation can actually grasp the moral, legal, or political gravity of drone targeting decisions or sentencing recommendations, much less reason wisely about them. But if an AI tool can make decisions—only faster and more cheaply—that are just as reliable as those made by the flawed humans who do reason about them, then the logic of efficiency invites us to let the reasoning drop out of the process.

It’s hard to demand an explanation from someone in power if they don’t have it and couldn’t get it even if they wanted to give it to you. For that reason, opaque AI decision systems are highly attractive tools for those in power; they offer a virtually bulletproof accountability shield.

In a future where this value is recognized, AI developers tasked with building a decision tool would ask themselves: What kinds of thinking does this system mirror or duplicate? Are those thought processes of no real value? Or are they among the thoughts that we must keep? Regulators of automated decision systems would ask: What justifies the impact of this system on the space of public reasons? Deployers of these systems would ask: How can this tool be used to preserve or augment, rather than shrink or eliminate, the space for human thought and reasoning in this organization? AI researchers would ask: How could the computational power of AI expand the space of reasons for people, and enable wider, more effective and equitable access to it?

The space of reasons has been constrained before—by priests, kings, oligarchs, and family elders who would gladly substitute their moral and political judgments for ours, and by bureaucrats who endlessly invent analog means of rendering their own judgments opaque. But at the heart of the modern Enlightenment lies the eighteenth-century philosopher Immanuel Kant’s urgent call: sapere aude! He asked us to dare to think for ourselves, together.

Chapter 5 The Empathy Box

An AI tool can create a new sea shanty or a new sculpture or a new abstract shape. But what can it express through these? To express is to have something inside oneself that needs to come out.

A generative AI model has nothing it needs to say, only an instruction to add some statistical noise to bend an existing pattern in a new direction.
